{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATIC MALWARE DETECTOR\n",
    "\n",
    "## This Malware Detector is generated using the features which are extracted from PE Headers as well as N-Grams of the samples which are \n",
    "\n",
    "### 1. Benign Samples\n",
    "### 2. Malicious Samples\n",
    "\n",
    "## After extracting we combine the features using scipy hstack and then train using the RandomForestClassifier and finally test the trained classifier\n",
    "\n",
    "## Packages to be Installed\n",
    "\n",
    "### 1. pefilem \n",
    "### 2. sklearn\n",
    "### 3. nltk\n",
    "\n",
    "pip install pefile sklearn nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Assigning labels to Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "\n",
    "directories_with_labels = [(\"Benign PE Samples\", 0), (\"Malicious PE Samples\", 1)]\n",
    "list_of_samples = []\n",
    "labels = []\n",
    "for dataset_path, label in directories_with_labels:\n",
    "    samples = [f for f in listdir(dataset_path)]\n",
    "    for sample in samples:\n",
    "        file_path = os.path.join(dataset_path, sample)\n",
    "        list_of_samples.append(file_path)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Following Convenience functions are introduced\n",
    "\n",
    "### 1. read_file :- Rads the binary file in binary sequence\n",
    "### 2. byte_sequence_to_Ngrams :- Creates N-grams from byte sequence\n",
    "### 3. binary_file_to_ngram_counts :- Outputs N-gram counts of the binary file\n",
    "### 4. get_Ngram_features_from_sample :- takes a sample and prodeces features depending on K-1Ngrams Selected\n",
    "### 5. preprocess_impoers :- Normalizes the names of the imports from the PE file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "import pefile\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, \"rb\") as binary_file:\n",
    "        data = binary_file.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "def byte_sequence_to_Ngrams(byte_sequence, N):\n",
    "    Ngrams = ngrams(byte_sequence, N)\n",
    "    return list(Ngrams)\n",
    "\n",
    "\n",
    "def binary_file_to_Ngram_counts(file, N):\n",
    "    filebyte_sequence = read_file(file)\n",
    "    file_Ngrams = byte_sequence_to_Ngrams(filebyte_sequence, N)\n",
    "    return collections.Counter(file_Ngrams)\n",
    "\n",
    "\n",
    "def get_NGram_features_from_sample(sample, K1_most_frequent_Ngrams_list):\n",
    "    K1 = len(K1_most_frequent_Ngrams_list)\n",
    "    feature_vector = K1 * [0]\n",
    "    file_Ngrams = binary_file_to_Ngram_counts(sample, N)\n",
    "    for i in range(K1):\n",
    "        feature_vector[i] = file_Ngrams[K1_most_frequent_Ngrams_list[i]]\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def preprocess_imports(list_of_DLLs):\n",
    "    temp = [x.decode().split(\".\")[0].lower() for x in list_of_DLLs]\n",
    "    return \" \".join(temp)\n",
    "\n",
    "\n",
    "def get_imports(pe):\n",
    "    list_of_imports = []\n",
    "    for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "        list_of_imports.append(entry.dll)\n",
    "    return preprocess_imports(list_of_imports)\n",
    "\n",
    "\n",
    "def get_section_names(pe):\n",
    "    list_of_section_names = []\n",
    "    for sec in pe.sections:\n",
    "        normalized_name = sec.Name.decode().replace(\"\\x00\", \"\").lower()\n",
    "        list_of_section_names.append(normalized_name)\n",
    "    return \"\".join(list_of_section_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Performing train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "samples_train, samples_test, labels_train, labels_test = train_test_split(\n",
    "    list_of_samples, labels, test_size=0.2, stratify=labels, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) We select 50 most frequent 2-grams as our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "Ngram_counts_all = collections.Counter([])\n",
    "for sample in samples_train:\n",
    "    Ngram_counts_all += binary_file_to_Ngram_counts(sample, N)\n",
    "K1 = 50\n",
    "K1_most_frequent_Ngrams = Ngram_counts_all.most_common(K1)\n",
    "K1_most_frequent_Ngrams_list = [x[0] for x in K1_most_frequent_Ngrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Extracting N-grams, Section names, imports and number of sections of each sample into training set \n",
    "\n",
    "## Skip over samples whose PE header cannot be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign PE Samples\\hvc.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\iisreset.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\CExecSvc.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\aspnetca.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\ldifde.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\ldp.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\LogCollector.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\c2wtshost.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dplaysvr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\adamuninstall.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\hvsirpcd.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\InetMgr6.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\InspectVhdDialog6.3.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\inetinfo.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\evntcmd.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dsacls.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\hvsirdpclient.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\evntwin.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\Build.exe:\n",
      "'utf-8' codec can't decode byte 0xd2 in position 6: invalid continuation byte\n",
      "Benign PE Samples\\InetMgr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\wirelesskeyview.exe:\n",
      "'utf-8' codec can't decode byte 0xff in position 1: invalid start byte\n",
      "Benign PE Samples\\lpq.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\ADSchemaAnalyzer.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\InspectVhdDialog6.2.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dsdbutil.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\CCG.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\malware.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Benign PE Samples\\cmak.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\BootExpCfg.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\hcsdiag.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\LxRun.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dpnsvr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dsmgmt.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\lpr.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\InspectVhdDialog.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\dsamain.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\iissetup.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\eshell.exe:\n",
      "'DOS Header magic not found.'\n",
      "Benign PE Samples\\appcmd.exe:\n",
      "'DOS Header magic not found.'\n"
     ]
    }
   ],
   "source": [
    "imports_corpus_train = []\n",
    "num_sections_train = []\n",
    "section_names_train = []\n",
    "Ngram_features_list_train = []\n",
    "y_train = []\n",
    "for i in range(len(samples_train)):\n",
    "    sample = samples_train[i]\n",
    "    try:\n",
    "        NGram_features = get_NGram_features_from_sample(\n",
    "            sample, K1_most_frequent_Ngrams_list\n",
    "        )\n",
    "        pe = pefile.PE(sample)\n",
    "        imports = get_imports(pe)\n",
    "        n_sections = len(pe.sections)\n",
    "        sec_names = get_section_names(pe)\n",
    "        imports_corpus_train.append(imports)\n",
    "        num_sections_train.append(n_sections)\n",
    "        section_names_train.append(sec_names)\n",
    "        Ngram_features_list_train.append(NGram_features)\n",
    "        y_train.append(labels_train[i])\n",
    "    except Exception as e:\n",
    "        print(sample + \":\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Converting imports and section names from text features into numerical form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "imports_featurizer = Pipeline(\n",
    "    [\n",
    "        (\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1, 2))),\n",
    "        (\"tfidf\", TfidfTransformer(use_idf=True,)),\n",
    "    ]\n",
    ")\n",
    "section_names_featurizer = Pipeline(\n",
    "    [\n",
    "        (\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1, 2))),\n",
    "        (\"tfidf\", TfidfTransformer(use_idf=True,)),\n",
    "    ]\n",
    ")\n",
    "imports_corpus_train_transformed = imports_featurizer.fit_transform(\n",
    "    imports_corpus_train\n",
    ")\n",
    "section_names_train_transformed = section_names_featurizer.fit_transform(\n",
    "    section_names_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Combining features into a single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "X_train = hstack(\n",
    "    [\n",
    "        Ngram_features_list_train,\n",
    "        imports_corpus_train_transformed,\n",
    "        section_names_train_transformed,\n",
    "        csr_matrix(num_sections_train).transpose(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Training a Random Forest Classifier on training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 100)\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "print(classifier.score(X_train, y_train)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Collecting Features of testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious PE Samples\\027cc450ef5f8c5f653329641ec1fed9.exe:\n",
      "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
      "Malicious PE Samples\\027cc450ef5f8c5f653329641ec1fed9.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\027cc450ef5f8c5f653329641ec1fed9.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\027cc450ef5f8c5f653329641ec1fed9.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\027cc450ef5f8c5f653329641ec1fed9.exe:\n",
      "'DOS Header magic not found.'\n",
      "Malicious PE Samples\\027cc450ef5f8c5f653329641ec1fed9.exe:\n",
      "'DOS Header magic not found.'\n"
     ]
    }
   ],
   "source": [
    "imports_corpus_test = []\n",
    "num_sections_test = []\n",
    "section_names_test = []\n",
    "Ngram_features_list_test = []\n",
    "y_test = []\n",
    "for i in range(len(samples_test)):\n",
    "    file = samples_test[i]\n",
    "    try:\n",
    "        NGram_features = get_NGram_features_from_sample(\n",
    "            sample, K1_most_frequent_Ngrams_list\n",
    "        )\n",
    "        pe = pefile.PE(file)\n",
    "        imports = get_imports(pe)\n",
    "        n_sections = len(pe.sections)\n",
    "        sec_names = get_section_names(pe)\n",
    "        imports_corpus_test.append(imports)\n",
    "        num_sections_test.append(n_sections)\n",
    "        section_names_test.append(sec_names)\n",
    "        Ngram_features_list_test.append(NGram_features)\n",
    "        y_test.append(labels_test[i])\n",
    "    except Exception as e:\n",
    "        print(sample + \":\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Testing Classifier on resulting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_corpus_test_transformed = imports_featurizer.transform(imports_corpus_test)\n",
    "section_names_test_transformed = section_names_featurizer.transform(section_names_test)\n",
    "X_test = hstack(\n",
    "    [\n",
    "        Ngram_features_list_test,\n",
    "        imports_corpus_test_transformed,\n",
    "        section_names_test_transformed,\n",
    "        csr_matrix(num_sections_test).transpose(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.67088607594937\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(X_test, y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
